apiVersion: v1
kind: Namespace
metadata:
  name: geneva
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-conf
  namespace: geneva
data:
  kubernetes.conf: |
    # This file collects and filters all Kubernetes container logs. Should rarely need to modify it.
    
    # Do not directly collect fluentd's own logs to avoid infinite loops.
    <label @FLUENT_LOG>
      <match fluent.**>
        @type null
      </match>
    </label>
    
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type multi_format
        # Read logs in JSON format for Kubernetes v1.18-
        <pattern>
          format json
          time_format "%Y-%m-%dT%H:%M:%S.%NZ"
          keep_time_key true
        </pattern>
        # Reads logs in CRI format for Kubernetes v1.19+
        # The CRI format is documented here: https://github.com/fluent/fluent-plugin-parser-cri
        <pattern>
          format regexp
          expression /^(?<time>.+) (?<stream>stdout|stderr)( (?<logtag>.))? (?<log>.*)$/
          time_format '%Y-%m-%dT%H:%M:%S.%N%:z'
          keep_time_key true
        </pattern>
      </parse>
    </source>
    
    <filter kubernetes.var.log.containers.**.log>
      @type kubernetes_metadata
    </filter>
    
    # Exclude events from Geneva containers since they just seem to echo events from other containers
    <filter kubernetes.var.log.containers.geneva**.log>
      @type grep
      <exclude>
        key log
        pattern .*
      </exclude>
    </filter>
    
    # Flatten fields nested within the 'log' field if it is JSON
    <filter kubernetes.var.log.containers.**.log>
      @type parser
      key_name log
      <parse>
        @type json
        json_parser json
      </parse>
      reserve_data true # this preserves fields from the original record
      remove_key_name_field true # this removes the log field if successfully parsed as JSON
      reserve_time # the time was already parsed in the source, we don't want to overwrite it with current time.
      emit_invalid_record_to_error false # In case of unparsable log lines or CRI logs. Keep fluentd's error log clean
    </filter>
    
    # Flatten fields nested within the 'kubernetes' field and remove unnecessary fields
    <filter kubernetes.var.log.containers.**.log>
      @type record_transformer
      enable_ruby   
      <record>    
        ContainerName ${record["kubernetes"]["container_name"]}
        NamespaceName ${record["kubernetes"]["namespace_name"]}    
        PodName ${record["kubernetes"]["pod_name"]}
        Node ${record["kubernetes"]["host"]}
        MasterUrl ${record["kubernetes"]["master_url"]}
      </record>
      # The logtag field is used in CRI to support multi-line logs. It is usually noise, so remove by default.
      # https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/kubelet-cri-logging.md
      remove_keys docker,kubernetes,stream,logtag
    </filter>
    
  fluentd.conf: |
    # This file collects, filters and sends logs to Geneva. You should modify it according to your specific needs.
    
    @include kubernetes.conf
    
    # Match tags generated by the kubernetes.conf config that correspond with one of our "application
    # containers". Retag them as "pmclogs.{container_name}" for streaming to mdsd / geneva.
    <match kubernetes.var.log.containers.{api-pod,worker-pod,pulp-content,nginx-content,nginx-api}**.log>
      @type rewrite_tag_filter
      <rule>
        key     ContainerName
        pattern ^(.+)$
        tag     pmclogs.$1
      </rule>
    </match>

    # Drop the endpoint monitor pings, because they're worthless and noisy
    <filter pmclogs.nginx-content>
      @type grep
      <exclude>
        key log
        pattern "Azure Traffic Manager Endpoint Monitor"
      </exclude>
    </filter>
    
    # Filter out ip address from the containers that log it
    <filter pmclogs.{nginx-content,pulp-content,pmc}>
      @type record_transformer
      enable_ruby
      <record>
        log ${record["log"].gsub(/(?:[0-9]{1,3}\.){3}[0-9]{1,3}/,'REDACTED_IP_ADDRESS')}
      </record>
    </filter>
    
    # Retag to prefix all other container events with k8scontainers
    <match kubernetes.var.log.containers.**.log>
      @type rewrite_tag_filter
      <rule>
        key     ContainerName
        pattern ^(.+)$
        tag     k8scontainers.$1
      </rule>
    </match>
    
    # Send pmclogs events to MDSD
    <match pmclogs.**>
      @type mdsd
      @log_level info
      djsonsocket /var/run/mdsd/default_djson.socket  # Full path to mdsd dynamic json socket file
      acktimeoutms 5000  # max time in milliseconds to wait for mdsd acknowledge response. If 0, no wait.
      mdsd_tag_regex_patterns ["^pmclogs\.\w+"]  # fluentd tag patterns whose match will be used as mdsd source name
      num_threads 1
      buffer_chunk_limit 1000k
      buffer_type file
      buffer_path /var/log/td-agent/buffer/out_pmclogs*.buffer
      buffer_queue_limit 128
      flush_interval 10s
      retry_limit 3
      retry_wait 10s
    </match>
    
    # Send all other kubernetes container events to MDSD
    <match k8scontainers.**>
      @type mdsd
      @log_level info
      djsonsocket /var/run/mdsd/default_djson.socket  # Full path to mdsd dynamic json socket file
      acktimeoutms 5000  # max time in milliseconds to wait for mdsd acknowledge response. If 0, no wait.
      mdsd_tag_regex_patterns ["^k8scontainers"]  # fluentd tag patterns whose match will be used as mdsd source name
      num_threads 1
      buffer_chunk_limit 1000k
      buffer_type file
      buffer_path /var/log/td-agent/buffer/out_k8scontainers*.buffer
      buffer_queue_limit 128
      flush_interval 10s
      retry_limit 3
      retry_wait 10s
    </match>
    
    # Anything else goes to standard output
    <match **>
      @type stdout
    </match>